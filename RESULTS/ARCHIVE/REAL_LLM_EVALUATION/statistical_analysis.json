{
  "model_performance": {
    "ChatGPT_4o": {
      "mean_f1": 0.1334323868222173,
      "std_f1": 0.019989937031745435,
      "mean_semantic": 0.07257622633463377,
      "mean_reasoning": 0.4083333333333333,
      "mean_domain": 0.47095959595959597,
      "mean_length": 234.25,
      "mean_uncertainty": 0.5,
      "sample_size": 4,
      "is_baseline": false
    },
    "GPT_o1": {
      "mean_f1": 0.0721281866434511,
      "std_f1": 0.020037018143472526,
      "mean_semantic": 0.05882033357974655,
      "mean_reasoning": 0.75,
      "mean_domain": 0.9583333333333334,
      "mean_length": 663.75,
      "mean_uncertainty": 0.5,
      "sample_size": 4,
      "is_baseline": false
    },
    "GPT_o1_Pro": {
      "mean_f1": 0.05849249991584529,
      "std_f1": 0.0047373234522443426,
      "mean_semantic": 0.05329698076787473,
      "mean_reasoning": 0.8416666666666666,
      "mean_domain": 1.0,
      "mean_length": 844.75,
      "mean_uncertainty": 1.5,
      "sample_size": 4,
      "is_baseline": false
    },
    "Claude_3_5_Sonnet": {
      "mean_f1": 0.12537361021866542,
      "std_f1": 0.029339692073599113,
      "mean_semantic": 0.09195440897110009,
      "mean_reasoning": 0.575,
      "mean_domain": 0.8888888888888888,
      "mean_length": 168.5,
      "mean_uncertainty": 1.5,
      "sample_size": 4,
      "is_baseline": false
    },
    "Gemini_2_0_Flash": {
      "mean_f1": 0.12985746609705137,
      "std_f1": 0.029712544101236547,
      "mean_semantic": 0.10469842775820005,
      "mean_reasoning": 0.5458333333333334,
      "mean_domain": 0.8198653198653199,
      "mean_length": 326.5,
      "mean_uncertainty": 1.0,
      "sample_size": 4,
      "is_baseline": false
    },
    "Mistral_Large_2": {
      "mean_f1": 0.1027013572509306,
      "std_f1": 0.017125329841583645,
      "mean_semantic": 0.08058224250610073,
      "mean_reasoning": 0.30833333333333335,
      "mean_domain": 0.42929292929292934,
      "mean_length": 264.75,
      "mean_uncertainty": 0.0,
      "sample_size": 4,
      "is_baseline": false
    },
    "Llama_3_1_405B": {
      "mean_f1": 0.15377187255903588,
      "std_f1": 0.04165600628025534,
      "mean_semantic": 0.08687828644223994,
      "mean_reasoning": 0.20833333333333331,
      "mean_domain": 0.5404040404040404,
      "mean_length": 363.25,
      "mean_uncertainty": 1.0,
      "sample_size": 4,
      "is_baseline": false
    },
    "DeepSeek_DeepThink_R1": {
      "mean_f1": 0.10974333252688145,
      "std_f1": 0.025242713814391474,
      "mean_semantic": 0.0769526677666002,
      "mean_reasoning": 0.48333333333333334,
      "mean_domain": 0.7441077441077442,
      "mean_length": 417.25,
      "mean_uncertainty": 1.75,
      "sample_size": 4,
      "is_baseline": false
    },
    "Random_Baseline": {
      "mean_f1": 0.2744514472455649,
      "std_f1": 0.11641516237999455,
      "mean_semantic": 0.20183823529411765,
      "mean_reasoning": 0.0,
      "mean_domain": 0.20833333333333334,
      "mean_length": 7.75,
      "mean_uncertainty": 0.0,
      "sample_size": 4,
      "is_baseline": true
    },
    "Frequency_Baseline": {
      "mean_f1": 0.28409090909090906,
      "std_f1": 0.11595364562567363,
      "mean_semantic": 0.32901337792642144,
      "mean_reasoning": 0.0,
      "mean_domain": 0.1388888888888889,
      "mean_length": 13.0,
      "mean_uncertainty": 0.0,
      "sample_size": 4,
      "is_baseline": true
    },
    "Keyword_Matching_Baseline": {
      "mean_f1": 0.2801701222753854,
      "std_f1": 0.15335766570959278,
      "mean_semantic": 0.11105889724310777,
      "mean_reasoning": 0.16666666666666666,
      "mean_domain": 0.2777777777777778,
      "mean_length": 11.0,
      "mean_uncertainty": 0.0,
      "sample_size": 4,
      "is_baseline": true
    },
    "Template_Baseline": {
      "mean_f1": 0.259648033126294,
      "std_f1": 0.13524034406217092,
      "mean_semantic": 0.29727066411849024,
      "mean_reasoning": 0.125,
      "mean_domain": 0.06944444444444445,
      "mean_length": 18.5,
      "mean_uncertainty": 0.0,
      "sample_size": 4,
      "is_baseline": true
    }
  },
  "baseline_comparisons": {
    "llm_mean_f1": 0.11068758900425979,
    "baseline_mean_f1": 0.27459012793453835,
    "improvement": -0.16390253893027856,
    "t_statistic": -6.354191142490561,
    "p_value": 8.510888904075481e-08,
    "effect_size": -1.6884649084656589,
    "significance": "significant"
  },
  "pairwise_comparisons": {
    "ChatGPT_4o_vs_GPT_o1": {
      "mean_diff": 0.06130420017876621,
      "t_statistic": 2.863795117830822,
      "p_value": 0.06437646377070935,
      "effect_size": 1.6534128821835608,
      "significance": "not_significant"
    },
    "ChatGPT_4o_vs_GPT_o1_Pro": {
      "mean_diff": 0.07493988690637202,
      "t_statistic": 6.2621734972349845,
      "p_value": 0.00821857938498276,
      "effect_size": 3.6154675543407575,
      "significance": "significant"
    },
    "ChatGPT_4o_vs_Claude_3_5_Sonnet": {
      "mean_diff": 0.008058776603551893,
      "t_statistic": 0.5565315840513515,
      "p_value": 0.6166664378493486,
      "effect_size": 0.3213136598645762,
      "significance": "not_significant"
    },
    "ChatGPT_4o_vs_Gemini_2_0_Flash": {
      "mean_diff": 0.0035749207251659365,
      "t_statistic": 0.19622465880578943,
      "p_value": 0.8569743839532228,
      "effect_size": 0.11329035958316455,
      "significance": "not_significant"
    },
    "ChatGPT_4o_vs_Mistral_Large_2": {
      "mean_diff": 0.030731029571286705,
      "t_statistic": 4.498411074578074,
      "p_value": 0.0205098711765694,
      "effect_size": 2.597158844833244,
      "significance": "significant"
    },
    "ChatGPT_4o_vs_Llama_3_1_405B": {
      "mean_diff": -0.02033948573681857,
      "t_statistic": -0.6189966989721325,
      "p_value": 0.5797445413558412,
      "effect_size": -0.3573779107790507,
      "significance": "not_significant"
    },
    "ChatGPT_4o_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": 0.023689054295335854,
      "t_statistic": 0.9683194752547065,
      "p_value": 0.40431058356946903,
      "effect_size": 0.5590595096998615,
      "significance": "not_significant"
    },
    "GPT_o1_vs_GPT_o1_Pro": {
      "mean_diff": 0.013635686727605803,
      "t_statistic": 1.3312390182228986,
      "p_value": 0.2752326979039693,
      "effect_size": 0.7685912055267234,
      "significance": "not_significant"
    },
    "GPT_o1_vs_Claude_3_5_Sonnet": {
      "mean_diff": -0.05324542357521432,
      "t_statistic": -1.976462360221848,
      "p_value": 0.14254715944822194,
      "effect_size": -1.141111075717247,
      "significance": "not_significant"
    },
    "GPT_o1_vs_Gemini_2_0_Flash": {
      "mean_diff": -0.05772927945360028,
      "t_statistic": -3.050485559537948,
      "p_value": 0.055406793105583364,
      "effect_size": -1.7611986589583,
      "significance": "not_significant"
    },
    "GPT_o1_vs_Mistral_Large_2": {
      "mean_diff": -0.030573170607479508,
      "t_statistic": -1.5028220138602184,
      "p_value": 0.22990757623826133,
      "effect_size": -0.8676546942462925,
      "significance": "not_significant"
    },
    "GPT_o1_vs_Llama_3_1_405B": {
      "mean_diff": -0.08164368591558478,
      "t_statistic": -5.2932201627574305,
      "p_value": 0.013156634396830073,
      "effect_size": -3.056042085847957,
      "significance": "significant"
    },
    "GPT_o1_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": -0.03761514588343036,
      "t_statistic": -4.441295685190991,
      "p_value": 0.021225526569365456,
      "effect_size": -2.5641832593957425,
      "significance": "significant"
    },
    "GPT_o1_Pro_vs_Claude_3_5_Sonnet": {
      "mean_diff": -0.06688111030282012,
      "t_statistic": -3.4614122631768063,
      "p_value": 0.04059850294203219,
      "effect_size": -1.9984473019214009,
      "significance": "significant"
    },
    "GPT_o1_Pro_vs_Gemini_2_0_Flash": {
      "mean_diff": -0.07136496618120608,
      "t_statistic": -4.839376426355591,
      "p_value": 0.01682943192028109,
      "effect_size": -2.7940152824663302,
      "significance": "significant"
    },
    "GPT_o1_Pro_vs_Mistral_Large_2": {
      "mean_diff": -0.04420885733508531,
      "t_statistic": -3.776480182267888,
      "p_value": 0.032521478839093,
      "effect_size": -2.180351849821652,
      "significance": "significant"
    },
    "GPT_o1_Pro_vs_Llama_3_1_405B": {
      "mean_diff": -0.09527937264319059,
      "t_statistic": -4.329041071426283,
      "p_value": 0.022729017674469953,
      "effect_size": -2.49937302792091,
      "significance": "significant"
    },
    "GPT_o1_Pro_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": -0.05125083261103616,
      "t_statistic": -3.463470605761138,
      "p_value": 0.040537886093561445,
      "effect_size": -1.9996356865665492,
      "significance": "significant"
    },
    "Claude_3_5_Sonnet_vs_Gemini_2_0_Flash": {
      "mean_diff": -0.004483855878385956,
      "t_statistic": -0.14378059568610493,
      "p_value": 0.8947886999319378,
      "effect_size": -0.08301176562361748,
      "significance": "not_significant"
    },
    "Claude_3_5_Sonnet_vs_Mistral_Large_2": {
      "mean_diff": 0.022672252967734813,
      "t_statistic": 2.6175925869488497,
      "p_value": 0.07916533275246489,
      "effect_size": 1.5112677847036873,
      "significance": "not_significant"
    },
    "Claude_3_5_Sonnet_vs_Llama_3_1_405B": {
      "mean_diff": -0.02839826234037046,
      "t_statistic": -0.695198020938263,
      "p_value": 0.5369403440913099,
      "effect_size": -0.4013727645288013,
      "significance": "not_significant"
    },
    "Claude_3_5_Sonnet_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": 0.01563027769178396,
      "t_statistic": 0.6153065155049927,
      "p_value": 0.5818804435049737,
      "effect_size": 0.355247382360938,
      "significance": "not_significant"
    },
    "Gemini_2_0_Flash_vs_Mistral_Large_2": {
      "mean_diff": 0.02715610884612077,
      "t_statistic": 1.190779802314624,
      "p_value": 0.319371901405207,
      "effect_size": 0.6874970394119178,
      "significance": "not_significant"
    },
    "Gemini_2_0_Flash_vs_Llama_3_1_405B": {
      "mean_diff": -0.023914406461984505,
      "t_statistic": -1.158047846812143,
      "p_value": 0.33066415594892096,
      "effect_size": -0.668599236091457,
      "significance": "not_significant"
    },
    "Gemini_2_0_Flash_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": 0.020114133570169918,
      "t_statistic": 0.750560020132288,
      "p_value": 0.50742271344485,
      "effect_size": 0.4333360296663473,
      "significance": "not_significant"
    },
    "Mistral_Large_2_vs_Llama_3_1_405B": {
      "mean_diff": -0.051070515308105274,
      "t_statistic": -1.5163236987643525,
      "p_value": 0.22670195764786352,
      "effect_size": -0.875449895660208,
      "significance": "not_significant"
    },
    "Mistral_Large_2_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": -0.007041975275950851,
      "t_statistic": -0.33393886657119076,
      "p_value": 0.7604065258949518,
      "effect_size": -0.19279969450775578,
      "significance": "not_significant"
    },
    "Llama_3_1_405B_vs_DeepSeek_DeepThink_R1": {
      "mean_diff": 0.04402854003215442,
      "t_statistic": 2.0032203274399105,
      "p_value": 0.138891961216627,
      "effect_size": 1.1565597952935625,
      "significance": "not_significant"
    }
  },
  "performance_distribution": {},
  "significance_tests": {}
}