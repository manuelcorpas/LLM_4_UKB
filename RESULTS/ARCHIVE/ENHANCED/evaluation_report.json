{
  "summary": {
    "total_models_evaluated": 5,
    "total_queries": 5,
    "query_complexities": [
      "simple_retrieval",
      "simple_retrieval",
      "complex_reasoning",
      "complex_reasoning",
      "hypothesis_generation"
    ],
    "evaluation_framework": "Enhanced LLM Evaluation with Precision/Recall"
  },
  "detailed_metrics": {
    "Gemini_2.0_Flash": {
      "avg_coverage_score": 0.6499999999999999,
      "avg_precision": 1.0,
      "avg_recall": 0.75,
      "avg_f1_score": 0.8055555555555556,
      "avg_semantic_accuracy": 0.4639694169163704,
      "avg_coherence_score": 0.0,
      "avg_reasoning_quality": 1.0,
      "total_error_types": 2
    },
    "ChatGPT_4o": {
      "avg_coverage_score": 0.7,
      "avg_precision": 1.0,
      "avg_recall": 0.6375,
      "avg_f1_score": 0.7420634920634921,
      "avg_semantic_accuracy": 0.4457917585968971,
      "avg_coherence_score": 0.25,
      "avg_reasoning_quality": 1.0,
      "total_error_types": 2
    },
    "Claude_Sonnet": {
      "avg_coverage_score": 0.6499999999999999,
      "avg_precision": 1.0,
      "avg_recall": 0.85,
      "avg_f1_score": 0.8928571428571429,
      "avg_semantic_accuracy": 0.46357499063014984,
      "avg_coherence_score": 0.0,
      "avg_reasoning_quality": 1.0,
      "total_error_types": 2
    },
    "Random_Baseline": {
      "avg_coverage_score": 0.29000000000000004,
      "avg_precision": 0.0,
      "avg_recall": 0.0,
      "avg_f1_score": 0.0,
      "avg_semantic_accuracy": 0.3393110156059265,
      "avg_coherence_score": 0.0,
      "avg_reasoning_quality": 0.8,
      "total_error_types": 2
    },
    "SimpleRule_Baseline": {
      "avg_coverage_score": 0.56,
      "avg_precision": 0.8,
      "avg_recall": 0.42000000000000004,
      "avg_f1_score": 0.5396825396825398,
      "avg_semantic_accuracy": 0.4646004974842072,
      "avg_coherence_score": 0.4,
      "avg_reasoning_quality": 0.8,
      "total_error_types": 2
    }
  },
  "model_comparison": {
    "Gemini_2.0_Flash_vs_ChatGPT_4o": {
      "f1_score_diff": 0.06349206349206349,
      "coverage_diff": -0.050000000000000044,
      "reasoning_diff": 0.0
    }
  },
  "baseline_comparison": {
    "Gemini_2.0_Flash_vs_Random": {
      "f1_improvement": 0.8055555555555556,
      "llm_f1": 0.8055555555555556,
      "baseline_f1": 0.0,
      "improvement_percentage": 0
    },
    "Gemini_2.0_Flash_vs_SimpleRule": {
      "f1_improvement": 0.2658730158730158,
      "llm_f1": 0.8055555555555556,
      "baseline_f1": 0.5396825396825398,
      "improvement_percentage": 49.26470588235292
    },
    "ChatGPT_4o_vs_Random": {
      "f1_improvement": 0.7420634920634921,
      "llm_f1": 0.7420634920634921,
      "baseline_f1": 0.0,
      "improvement_percentage": 0
    },
    "ChatGPT_4o_vs_SimpleRule": {
      "f1_improvement": 0.20238095238095233,
      "llm_f1": 0.7420634920634921,
      "baseline_f1": 0.5396825396825398,
      "improvement_percentage": 37.499999999999986
    },
    "Claude_Sonnet_vs_Random": {
      "f1_improvement": 0.8928571428571429,
      "llm_f1": 0.8928571428571429,
      "baseline_f1": 0.0,
      "improvement_percentage": 0
    },
    "Claude_Sonnet_vs_SimpleRule": {
      "f1_improvement": 0.35317460317460314,
      "llm_f1": 0.8928571428571429,
      "baseline_f1": 0.5396825396825398,
      "improvement_percentage": 65.44117647058822
    }
  },
  "complexity_analysis": {}
}